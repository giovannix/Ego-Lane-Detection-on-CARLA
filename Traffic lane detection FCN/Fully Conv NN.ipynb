{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This file contains code for a fully convolutional\n",
    "(i.e. contains zero fully connected layers) neural network\n",
    "for detecting lanes. This version assumes the inputs\n",
    "to be road images in the shape of 80 x 160 x 3 (RGB) with\n",
    "the labels as 80 x 160 x 1 (just the G channel with a\n",
    "re-drawn lane). Note that in order to view a returned image,\n",
    "the predictions is later stacked with zero'ed R and B layers\n",
    "and added back to the initial road image.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import necessary items from Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, pool_size):\n",
    "    # Create the actual neural network here\n",
    "    model = Sequential()\n",
    "    # Normalizes incoming inputs. First layer needs the input shape to work\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    # Below layers were re-named for easier reading of model summary; this not necessary\n",
    "    # Conv Layer 1\n",
    "    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # Pooling 1\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 3\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 4\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 5\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Pooling 2\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 6\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 7\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Pooling 3\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Upsample 1\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 1\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 2\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Upsample 2\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 3\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 4\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Deconv 5\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Upsample 3\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 6\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "    # Final layer - only including one channel so 1 filter\n",
    "    model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_images = pickle.load(open(\"./data/images.pkl\", \"rb\" ))\n",
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"./data/labels.pkl\", \"rb\" ))\n",
    "\n",
    "# Make into arrays as the neural network wants these\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize labels - training images get normalized to start in the network\n",
    "labels = labels / 255\n",
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)\n",
    "\n",
    "# Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Create the neural network\n",
    "model = create_model(input_shape, pool_size)\n",
    "\n",
    "# Using a generator to help the model use less data\n",
    "# Channel shifts help with shadows slightly\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "# Save model architecture and weights\n",
    "model.save('full_CNN_model.h5')\n",
    "\n",
    "# Show summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
